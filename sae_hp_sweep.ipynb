{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/15 [00:00<?, ?it/s]Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'sae_size': 16384, 'sae_learning_rate': 5e-05, 'sae_sparsity_penalty': 200, 'model_embedding_layer': 6, 'eval_interval': 500, 'max_iters': 60000, 'H': 32, 'B': 64, 'T': 256, 'C': 256, 'feedforward_factor': 3, 'n_heads': 8, 'n_layers': 12, 'tokenizer_vocab_size': 8192, 'git_hash': 'a2412eeaa63a6b177ae3662d5caece80baca8b96'}\n",
      "Total trainable parameters: 8405248\n",
      "val loss on next datafile\n",
      "train loss on next datafile\n",
      "training on residuals/residuals_train_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51187/51187 [01:22<00:00, 622.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss on next datafile\n",
      "train loss on next datafile\n",
      "training on residuals/residuals_train_11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51187/51187 [01:49<00:00, 465.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss on next datafile\n",
      "train loss on next datafile\n",
      "training on residuals/residuals_train_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import torch\n",
    "from activated_notebook_importer import import_notebook\n",
    "\n",
    "\n",
    "# Assuming you have a test notebook file\n",
    "def train(sparsity_penalty):\n",
    "    module = import_notebook('train_sae.ipynb', {'sae_sparsity_penalty': sparsity_penalty})\n",
    "    results = module.train_loop()\n",
    "    torch.cuda.empty_cache()\n",
    "    results['sparsity_penalty'] = sparsity_penalty\n",
    "    return results\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "for sparsity_penalty in tqdm(range(200, 350, 10), desc=\"Training\"):\n",
    "    results.append(train(sparsity_penalty))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reconstruction_loss': 0.5366029888391495, 'sparsity_loss': 1.71414315700531, 'total_loss': 2.250746190547943, 'r2_per_channel': 0.7846678048372269, 'active_features_per_token': 81.8671875}\n",
      "{'reconstruction_loss': 0.8373714536428452, 'sparsity_loss': 2.759241282939911, 'total_loss': 3.5966127514839172, 'r2_per_channel': 0.6690417379140854, 'active_features_per_token': 87.95703125}\n",
      "{'reconstruction_loss': 0.6390546560287476, 'sparsity_loss': 2.9320902228355408, 'total_loss': 3.5711448788642883, 'r2_per_channel': 0.7377705276012421, 'active_features_per_token': 71.9140625}\n",
      "{'reconstruction_loss': 1.2683676183223724, 'sparsity_loss': 3.369257092475891, 'total_loss': 4.637624740600586, 'r2_per_channel': 0.4915945455431938, 'active_features_per_token': 95.98828125}\n",
      "{'reconstruction_loss': 0.6677848547697067, 'sparsity_loss': 1.9693474769592285, 'total_loss': 2.6371323466300964, 'r2_per_channel': 0.7387693822383881, 'active_features_per_token': 57.45703125}\n",
      "{'reconstruction_loss': 0.6794921159744263, 'sparsity_loss': 2.330107629299164, 'total_loss': 3.00959974527359, 'r2_per_channel': 0.7439096570014954, 'active_features_per_token': 75.03125}\n",
      "{'reconstruction_loss': 0.8370130062103271, 'sparsity_loss': 2.5442049503326416, 'total_loss': 3.3812179565429688, 'r2_per_channel': 0.6835168302059174, 'active_features_per_token': 63.9921875}\n",
      "{'reconstruction_loss': 0.7784375995397568, 'sparsity_loss': 3.2963783740997314, 'total_loss': 4.074815988540649, 'r2_per_channel': 0.6919916421175003, 'active_features_per_token': 58.53125}\n",
      "{'reconstruction_loss': 0.7514997720718384, 'sparsity_loss': 2.8402916193008423, 'total_loss': 3.5917914509773254, 'r2_per_channel': 0.7161838561296463, 'active_features_per_token': 57.515625}\n",
      "{'reconstruction_loss': 0.8315868079662323, 'sparsity_loss': 2.5231521129608154, 'total_loss': 3.3547388315200806, 'r2_per_channel': 0.6866130232810974, 'active_features_per_token': 61.65625}\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
